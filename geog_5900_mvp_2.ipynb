{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GEOG 5900 - MVP\n",
    "\n",
    "### Author: Jacob Harris\n",
    "### Date: 2024/12/03\n",
    "\n",
    "#### Updates from last version\n",
    "- Functionality: Saves metadata for each image as a csv\n",
    "- UI: Uses Chrome Driver to view scraping\n",
    "- Quality of Life: Adds limit to the number of images that the script will download (per prompt)\n",
    "#### Description\n",
    "- The following script is meant to scrapes images from the Umedia website. This way, you have an automated method for downloading historical images of certain buildings\n",
    "- If you want to replicate this script, you'll need to install the required packages and change the 'please have your directory organized like the following. Place this script into the 'scripts' directory and place the 'prompts_test.csv' into the 'data' directory.\n",
    "\n",
    "![image info](../data/dir.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CURRENT WORKING DIR = /Users/jakeharris/Files/geog_5900/scripts\n"
     ]
    }
   ],
   "source": [
    "# set dirs\n",
    "print('CURRENT WORKING DIR =', os.getcwd())\n",
    "data_dir = '../data'\n",
    "save_dir = os.path.join(data_dir, 'images')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scrape images and metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate a unique file name by appending a counter if necessary\n",
    "def generate_unique_filename(file_path):\n",
    "    base, extension = os.path.splitext(file_path)\n",
    "    counter = 1\n",
    "    while os.path.exists(file_path):\n",
    "        file_path = f\"{base}_{counter}{extension}\"\n",
    "        counter += 1\n",
    "    return file_path\n",
    "\n",
    "# Function to download and save the image in the specified directory\n",
    "def download_image(image_url, image_title, directory):\n",
    "    try:\n",
    "        # Ensure the directory exists\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "        \n",
    "        # Construct the full file path\n",
    "        image_path = os.path.join(directory, f\"{image_title}.png\")\n",
    "        \n",
    "        # Ensure the file name is unique by adding a counter if needed\n",
    "        unique_image_path = generate_unique_filename(image_path)\n",
    "        \n",
    "        # Download the image\n",
    "        response = requests.get(image_url, stream=True)\n",
    "        if response.status_code == 200:\n",
    "            with open(unique_image_path, 'wb') as file:\n",
    "                for chunk in response.iter_content(1024):\n",
    "                    file.write(chunk)\n",
    "            print(f\"Image saved as {unique_image_path}\")\n",
    "            return unique_image_path\n",
    "        else:\n",
    "            print(f\"Failed to download image: {image_url}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading image: {e}\")\n",
    "    return None\n",
    "\n",
    "# Function to extract metadata from a page\n",
    "def extract_metadata(page_soup):\n",
    "    metadata = []\n",
    "\n",
    "    # Find all <h3> tags (which represent the categories)\n",
    "    for h3 in page_soup.find_all('h3'):\n",
    "        category = h3.get_text(strip=True)\n",
    "        \n",
    "        # Find the next <dl> sibling after <h3>\n",
    "        dl = h3.find_next_sibling('dl')\n",
    "        if dl:\n",
    "            # Collect all <dt> and <dd> pairs as \"dt_text = dd_text\"\n",
    "            details_list = []\n",
    "            for dt, dd in zip(dl.find_all('dt'), dl.find_all('dd')):\n",
    "                dt_text = dt.get_text(strip=True)\n",
    "                dd_text = dd.get_text(strip=True)\n",
    "                details_list.append(f\"{dt_text} = {dd_text}\")\n",
    "            \n",
    "            # Combine all details for the \"details\" column\n",
    "            details = ' '.join(details_list)\n",
    "            metadata.append({\"category\": category, \"details\": details})\n",
    "    return metadata\n",
    "\n",
    "# Combined function to scrape images and metadata\n",
    "def scrape_images_and_metadata(prompt, chrome_driver_path):\n",
    "    print('-----------------------------------\\n* GEOG 5900 - FALL 2024\\n* Author: JACOB HARRIS\\n* Project: 3D Modeling of West Bank\\n-----------------------------------')\n",
    "    # Set up the Chrome driver using the specified driver path\n",
    "    service = Service(chrome_driver_path)\n",
    "    driver = webdriver.Chrome(service=service)\n",
    "    \n",
    "    # set dir and url\n",
    "    \n",
    "    # Base url for Umedia\n",
    "    base_url = 'https://umedia.lib.umn.edu/search?facets%5Bcollection_name_s%5D%5B%5D=University+of+Minnesota+Archives+Photograph+Collection&q='\n",
    "    # Change underscores (or spaces) in prompt to \"+\" since that is what the req format for the url\n",
    "    prompt_formatted = prompt.replace('_', '+') \n",
    "    # Append prompt that is formatted for URL to the Umedia base url\n",
    "    main_url = base_url + prompt_formatted # This is the final url to scrape from\n",
    "\n",
    "    directory = os.path.join(save_dir, prompt) # The directory where images will be saved\n",
    "\n",
    "    data = []\n",
    "    image_counter = 0  # Counter to track the number of images downloaded\n",
    "    download_lim = 5 # Limit to the number of images that will download per prompt\n",
    "\n",
    "    try:\n",
    "        # Load the main page\n",
    "        print(f\"Loading main page: {main_url}\")\n",
    "        driver.get(main_url)\n",
    "        time.sleep(2)  # Allow time for the page to load\n",
    "\n",
    "        # Parse the HTML content of the main page\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        \n",
    "        # Find all <a> tags with class \"search-result-item-title\"\n",
    "        result_links = soup.find_all('a', class_='search-result-item-title')\n",
    "        \n",
    "        for result in result_links:\n",
    "            if image_counter >= download_lim:\n",
    "                print(f\"Reached the limit of {download_lim} images... terminating function.\")\n",
    "                break\n",
    "\n",
    "            title = result.text.strip()  # Use the text as the title\n",
    "            page_url = urljoin(main_url, result['href'])  # Construct full URL\n",
    "            \n",
    "            # Visit each link\n",
    "            print(f\"Navigating to: {page_url}\")\n",
    "            driver.get(page_url)\n",
    "            time.sleep(2)  # Wait for the page to fully load\n",
    "            \n",
    "            # Parse the new page content\n",
    "            page_soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "            \n",
    "            # Extract metadata from the page\n",
    "            metadata = extract_metadata(page_soup)\n",
    "            for entry in metadata:\n",
    "                entry[\"title\"] = title  # Add the title to each metadata entry\n",
    "                data.append(entry)\n",
    "            \n",
    "            # Find the <a> tag for the \"Full-size image\" download\n",
    "            download_link = page_soup.find('a', class_='large-download', string=\"Full-size image\")\n",
    "            if download_link and 'href' in download_link.attrs:\n",
    "                image_url = urljoin(page_url, download_link['href'])  # Handle relative URLs with urljoin\n",
    "                print(f\"Found image URL: {image_url}\")\n",
    "                \n",
    "                # Download the image and save it in the specified directory\n",
    "                download_image(image_url, title, directory)\n",
    "                image_counter += 1  # Increment the counter\n",
    "                print(f\"Progress: Downloaded {image_counter}/{download_lim} images.\")\n",
    "            else:\n",
    "                print(f\"No 'Full-size image' link found on page: {page_url}\")\n",
    "    finally:\n",
    "        driver.quit()  # Ensure the browser closes after execution\n",
    "    \n",
    "    # Convert the collected metadata into a Pandas DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Call functions with a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to accept a csv file of prompts\n",
    "def scrape_from_df(csv_file):\n",
    "\n",
    "    # Path to chrom driver (CHANGE TO YOUR OWN PATH)\n",
    "    chrome_driver_path = '/Users/jakeharris/Dev_tools/chromedriver-mac-arm64/chromedriver'\n",
    "    # Dict to save dfs\n",
    "    meta_dict = {}\n",
    "\n",
    "    # Load csv file (stored in the data directory)\n",
    "    prompts_file = os.path.join(data_dir, csv_file) \n",
    "    # Read in prompts csv as a pandas df \n",
    "    prompts_df = pd.read_csv(prompts_file)\n",
    "\n",
    "    # Iterate through each row of the df 'Prompt' column\n",
    "    for index, prompt in prompts_df['Prompt'].items():\n",
    "        # Call the function with each row in the 'Prompts' column\n",
    "        metadata_df = scrape_images_and_metadata(prompt, chrome_driver_path)\n",
    "        # Save metadata to dict\n",
    "        meta_dict[prompt] = metadata_df\n",
    "\n",
    "    # Save metadata locally \n",
    "\n",
    "    meta_dir = os.path.join(data_dir, 'metadata')\n",
    "    # Ensure the directory exists\n",
    "    if not os.path.exists(meta_dir):\n",
    "        os.makedirs(meta_dir)\n",
    "    \n",
    "    for name, df in meta_dict.items():\n",
    "        meta_filename = f'{name}.csv'\n",
    "        save_path = os.path.join(meta_dir, meta_filename)\n",
    "        df.to_csv(save_path, index=False)  # Save each df as a CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "* GEOG 5900 - FALL 2024\n",
      "* Author: JACOB HARRIS\n",
      "* Project: 3D Modeling of West Bank\n",
      "-----------------------------------\n",
      "Loading main page: https://umedia.lib.umn.edu/search?facets%5Bcollection_name_s%5D%5B%5D=University+of+Minnesota+Archives+Photograph+Collection&q=Heller Hall\n",
      "Navigating to: https://umedia.lib.umn.edu/item/p16022coll175:10102?facets%5Bcollection_name_s%5D%5B%5D=University+of+Minnesota+Archives+Photograph+Collection&q=Heller+Hall\n",
      "Found image URL: https://cdm16022.contentdm.oclc.org/utils/ajaxhelper?CISOROOT=p16022coll175&CISOPTR=10102&action=2&DMSCALE=100&DMWIDTH=3708&DMHEIGHT=4699\n",
      "Image saved as ../data/images/Heller Hall/Heller, Walter_3.png\n",
      "Progress: Downloaded 1/5 images.\n",
      "Navigating to: https://umedia.lib.umn.edu/item/p16022coll175:2242?facets%5Bcollection_name_s%5D%5B%5D=University+of+Minnesota+Archives+Photograph+Collection&q=Heller+Hall\n",
      "Found image URL: https://cdm16022.contentdm.oclc.org/utils/ajaxhelper?CISOROOT=p16022coll175&CISOPTR=2242&action=2&DMSCALE=100&DMWIDTH=2926&DMHEIGHT=2368\n",
      "Image saved as ../data/images/Heller Hall/Campus Views. Minneapolis Campus. West Bank_6.png\n",
      "Progress: Downloaded 2/5 images.\n",
      "Navigating to: https://umedia.lib.umn.edu/item/p16022coll175:2797?facets%5Bcollection_name_s%5D%5B%5D=University+of+Minnesota+Archives+Photograph+Collection&q=Heller+Hall\n",
      "Found image URL: https://cdm16022.contentdm.oclc.org/utils/ajaxhelper?CISOROOT=p16022coll175&CISOPTR=2797&action=2&DMSCALE=100&DMWIDTH=2884&DMHEIGHT=2368\n",
      "Image saved as ../data/images/Heller Hall/Campus Views. Minneapolis Campus. West Bank_7.png\n",
      "Progress: Downloaded 3/5 images.\n",
      "Navigating to: https://umedia.lib.umn.edu/item/p16022coll175:4988?facets%5Bcollection_name_s%5D%5B%5D=University+of+Minnesota+Archives+Photograph+Collection&q=Heller+Hall\n",
      "Found image URL: https://cdm16022.contentdm.oclc.org/utils/ajaxhelper?CISOROOT=p16022coll175&CISOPTR=4988&action=2&DMSCALE=100&DMWIDTH=642&DMHEIGHT=905\n",
      "Image saved as ../data/images/Heller Hall/Business Administration Tower. Heller Hall. Minneapolis Campus_6.png\n",
      "Progress: Downloaded 4/5 images.\n",
      "Navigating to: https://umedia.lib.umn.edu/item/p16022coll175:1082?facets%5Bcollection_name_s%5D%5B%5D=University+of+Minnesota+Archives+Photograph+Collection&q=Heller+Hall\n",
      "Found image URL: https://cdm16022.contentdm.oclc.org/utils/ajaxhelper?CISOROOT=p16022coll175&CISOPTR=1082&action=2&DMSCALE=100&DMWIDTH=2984&DMHEIGHT=2426\n",
      "Image saved as ../data/images/Heller Hall/Business Administration Tower. Heller Hall. Minneapolis Campus_7.png\n",
      "Progress: Downloaded 5/5 images.\n",
      "Reached the limit of 5 images... terminating function.\n",
      "-----------------------------------\n",
      "* GEOG 5900 - FALL 2024\n",
      "* Author: JACOB HARRIS\n",
      "* Project: 3D Modeling of West Bank\n",
      "-----------------------------------\n",
      "Loading main page: https://umedia.lib.umn.edu/search?facets%5Bcollection_name_s%5D%5B%5D=University+of+Minnesota+Archives+Photograph+Collection&q=Humphrey  Center\n",
      "Navigating to: https://umedia.lib.umn.edu/item/p16022coll175:237?facets%5Bcollection_name_s%5D%5B%5D=University+of+Minnesota+Archives+Photograph+Collection&q=Humphrey++Center\n",
      "Found image URL: https://cdm16022.contentdm.oclc.org/utils/ajaxhelper?CISOROOT=p16022coll175&CISOPTR=237&action=2&DMSCALE=100&DMWIDTH=4852&DMHEIGHT=5926\n",
      "Image saved as ../data/images/Humphrey  Center/Hubert H. Humphrey Center. Minneapolis Campus_9.png\n",
      "Progress: Downloaded 1/5 images.\n",
      "Navigating to: https://umedia.lib.umn.edu/item/p16022coll175:2084?facets%5Bcollection_name_s%5D%5B%5D=University+of+Minnesota+Archives+Photograph+Collection&q=Humphrey++Center\n",
      "Found image URL: https://cdm16022.contentdm.oclc.org/utils/ajaxhelper?CISOROOT=p16022coll175&CISOPTR=2084&action=2&DMSCALE=100&DMWIDTH=4852&DMHEIGHT=5926\n",
      "Image saved as ../data/images/Humphrey  Center/Hubert H. Humphrey Center. Minneapolis Campus_10.png\n",
      "Progress: Downloaded 2/5 images.\n",
      "Navigating to: https://umedia.lib.umn.edu/item/p16022coll175:2658?facets%5Bcollection_name_s%5D%5B%5D=University+of+Minnesota+Archives+Photograph+Collection&q=Humphrey++Center\n",
      "Found image URL: https://cdm16022.contentdm.oclc.org/utils/ajaxhelper?CISOROOT=p16022coll175&CISOPTR=2658&action=2&DMSCALE=100&DMWIDTH=5957&DMHEIGHT=4126\n",
      "Image saved as ../data/images/Humphrey  Center/Hubert H. Humphrey Center. Minneapolis Campus_11.png\n",
      "Progress: Downloaded 3/5 images.\n",
      "Navigating to: https://umedia.lib.umn.edu/item/p16022coll175:3233?facets%5Bcollection_name_s%5D%5B%5D=University+of+Minnesota+Archives+Photograph+Collection&q=Humphrey++Center\n",
      "Found image URL: https://cdm16022.contentdm.oclc.org/utils/ajaxhelper?CISOROOT=p16022coll175&CISOPTR=3233&action=2&DMSCALE=100&DMWIDTH=5915&DMHEIGHT=4157\n",
      "Image saved as ../data/images/Humphrey  Center/Hubert H. Humphrey Center. Minneapolis Campus_12.png\n",
      "Progress: Downloaded 4/5 images.\n",
      "Navigating to: https://umedia.lib.umn.edu/item/p16022coll175:3053?facets%5Bcollection_name_s%5D%5B%5D=University+of+Minnesota+Archives+Photograph+Collection&q=Humphrey++Center\n",
      "Found image URL: https://cdm16022.contentdm.oclc.org/utils/ajaxhelper?CISOROOT=p16022coll175&CISOPTR=3053&action=2&DMSCALE=100&DMWIDTH=5831&DMHEIGHT=4126\n",
      "Image saved as ../data/images/Humphrey  Center/Hubert H. Humphrey Center. Minneapolis Campus_13.png\n",
      "Progress: Downloaded 5/5 images.\n",
      "Reached the limit of 5 images... terminating function.\n",
      "-----------------------------------\n",
      "* GEOG 5900 - FALL 2024\n",
      "* Author: JACOB HARRIS\n",
      "* Project: 3D Modeling of West Bank\n",
      "-----------------------------------\n",
      "Loading main page: https://umedia.lib.umn.edu/search?facets%5Bcollection_name_s%5D%5B%5D=University+of+Minnesota+Archives+Photograph+Collection&q=Social Sciences Building\n",
      "Navigating to: https://umedia.lib.umn.edu/item/p16022coll175:6189?facets%5Bcollection_name_s%5D%5B%5D=University+of+Minnesota+Archives+Photograph+Collection&q=Social+Sciences+Building\n",
      "Found image URL: https://cdm16022.contentdm.oclc.org/utils/ajaxhelper?CISOROOT=p16022coll175&CISOPTR=6189&action=2&DMSCALE=100&DMWIDTH=5955&DMHEIGHT=4866\n",
      "Image saved as ../data/images/Social Sciences Building/Social Science Building. Duluth Campus. Construction_1.png\n",
      "Progress: Downloaded 1/5 images.\n",
      "Navigating to: https://umedia.lib.umn.edu/item/p16022coll175:3866?facets%5Bcollection_name_s%5D%5B%5D=University+of+Minnesota+Archives+Photograph+Collection&q=Social+Sciences+Building\n",
      "Found image URL: https://cdm16022.contentdm.oclc.org/utils/ajaxhelper?CISOROOT=p16022coll175&CISOPTR=3866&action=2&DMSCALE=100&DMWIDTH=1648&DMHEIGHT=1744\n",
      "Image saved as ../data/images/Social Sciences Building/Students gathering on campus with a sign, \"U of M on Strike\"_1.png\n",
      "Progress: Downloaded 2/5 images.\n",
      "Navigating to: https://umedia.lib.umn.edu/item/p16022coll175:3998?facets%5Bcollection_name_s%5D%5B%5D=University+of+Minnesota+Archives+Photograph+Collection&q=Social+Sciences+Building\n",
      "Found image URL: https://cdm16022.contentdm.oclc.org/utils/ajaxhelper?CISOROOT=p16022coll175&CISOPTR=3998&action=2&DMSCALE=100&DMWIDTH=5035&DMHEIGHT=6090\n",
      "Image saved as ../data/images/Social Sciences Building/Campus Views. Mpls. West. Construction of Social Sciences Tower, Business Administration Tower._1.png\n",
      "Progress: Downloaded 3/5 images.\n",
      "Navigating to: https://umedia.lib.umn.edu/item/p16022coll175:2329?facets%5Bcollection_name_s%5D%5B%5D=University+of+Minnesota+Archives+Photograph+Collection&q=Social+Sciences+Building\n",
      "Found image URL: https://cdm16022.contentdm.oclc.org/utils/ajaxhelper?CISOROOT=p16022coll175&CISOPTR=2329&action=2&DMSCALE=100&DMWIDTH=2838&DMHEIGHT=2238\n",
      "Image saved as ../data/images/Social Sciences Building/Campus Views. Mpls. West. Anderson Hall, Social Sciences, Business Administration_1.png\n",
      "Progress: Downloaded 4/5 images.\n",
      "Navigating to: https://umedia.lib.umn.edu/item/p16022coll175:4983?facets%5Bcollection_name_s%5D%5B%5D=University+of+Minnesota+Archives+Photograph+Collection&q=Social+Sciences+Building\n",
      "Found image URL: https://cdm16022.contentdm.oclc.org/utils/ajaxhelper?CISOROOT=p16022coll175&CISOPTR=4983&action=2&DMSCALE=100&DMWIDTH=2832&DMHEIGHT=2256\n",
      "Image saved as ../data/images/Social Sciences Building/Campus Views. Minneapolis Campus West._1.png\n",
      "Progress: Downloaded 5/5 images.\n",
      "Reached the limit of 5 images... terminating function.\n"
     ]
    }
   ],
   "source": [
    "# Call scrape from df function \n",
    "test_file_name = 'prompts_test.csv'\n",
    "data_dict = scrape_from_df(test_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Script Complete\n",
    "\n",
    "- Navigate to the '../data/images/' directory to see the images that you downloaded\n",
    "- Navigate to the '../data/metadata/' directory to see the metadata for each image that you downloaded"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geog_5900",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
